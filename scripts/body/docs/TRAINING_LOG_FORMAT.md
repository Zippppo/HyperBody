# è®­ç»ƒæ—¥å¿—æ–‡ä»¶æ ¼å¼è¯´æ˜

æ”¹è¿›åçš„ `train_body.py` ä¼šè‡ªåŠ¨ä¿å­˜å®Œæ•´çš„è®­ç»ƒä¿¡æ¯åˆ°ä»¥ä¸‹æ–‡ä»¶ï¼š

## ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„

```
logs/
â””â”€â”€ body_unet_bs2_lr0.0001_ch32_cw0.5_aug/
    â”œâ”€â”€ training_config.json      # è®­ç»ƒé…ç½®ï¼ˆå¯åŠ¨æ—¶ä¿å­˜ï¼‰
    â”œâ”€â”€ training_log.json          # è®­ç»ƒè¿‡ç¨‹è®°å½•ï¼ˆæ¯ä¸ªepochæ›´æ–°ï¼‰
    â”œâ”€â”€ training_summary.json      # è®­ç»ƒæ€»ç»“ï¼ˆå®Œæˆæ—¶ä¿å­˜ï¼‰
    â”œâ”€â”€ checkpoints/
    â”‚   â””â”€â”€ best_model.ckpt        # æœ€ä½³æ¨¡å‹æƒé‡ï¼ˆä»…ä¿å­˜æœ€ä½³ï¼‰
    â””â”€â”€ version_X/                 # TensorBoardæ—¥å¿—
        â””â”€â”€ events.out.tfevents.*
```

---

## 1ï¸âƒ£ `training_config.json` - è®­ç»ƒé…ç½®

**ä¿å­˜æ—¶æœº**ï¼šè®­ç»ƒå¼€å§‹æ—¶
**å†…å®¹**ï¼šå®Œæ•´çš„è®­ç»ƒå‚æ•°é…ç½®

```json
{
  "experiment": {
    "name": "body_unet",
    "start_time": "2024-01-15 10:30:00",
    "log_dir": "logs"
  },
  "data": {
    "dataset_root": "voxel-output/merged_data",
    "target_size": [160, 160, 256],
    "batch_size": 2,
    "num_workers": 4,
    "data_aug": true
  },
  "model": {
    "n_classes": 71,
    "base_channels": 32,
    "use_light_model": false,
    "total_parameters": 20458391
  },
  "training": {
    "lr": 0.0001,
    "weight_decay": 0.0,
    "max_epochs": 100,
    "warmup_epochs": 5,
    "n_gpus": 2,
    "precision": "16",
    "seed": 42
  },
  "loss": {
    "use_class_weights": true,
    "weight_alpha": 0.5,
    "class_weights_stats": {
      "min": 0.123,
      "max": 5.678,
      "mean": 1.234,
      "std": 0.987
    }
  },
  "system": {
    "pytorch_version": "1.13.0+cu117",
    "cuda_available": true,
    "cuda_version": "11.7"
  }
}
```

---

## 2ï¸âƒ£ `training_log.json` - è®­ç»ƒè¿‡ç¨‹è®°å½•

**ä¿å­˜æ—¶æœº**ï¼šæ¯ä¸ªepochåè‡ªåŠ¨æ›´æ–°
**å†…å®¹**ï¼šå®Œæ•´çš„è®­ç»ƒå†å²æ›²çº¿

```json
{
  "training_history": {
    "epoch": [0, 1, 2, 3, 4, 5],
    "train_loss": [2.456, 1.987, 1.654, 1.432, 1.298, 1.187],
    "train_accuracy": [0.234, 0.356, 0.445, 0.512, 0.567, 0.612],
    "val_loss": [2.123, 1.876, 1.598, 1.387, 1.245, 1.134],
    "val_mIoU": [0.156, 0.234, 0.298, 0.345, 0.389, 0.421],
    "learning_rate": [0.00002, 0.00004, 0.00006, 0.00008, 0.0001, 0.0001]
  },
  "best_metrics": {
    "best_val_mIoU": 0.421,
    "best_epoch": 5
  },
  "last_update": "2024-01-15 12:45:30"
}
```

**ç”¨é€”**ï¼š
- ç»˜åˆ¶è®­ç»ƒæ›²çº¿
- åˆ†æè®­ç»ƒè¿‡ç¨‹
- ç›‘æ§è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ
- å­¦ä¹ ç‡è°ƒæ•´å‚è€ƒ

---

## 3ï¸âƒ£ `training_summary.json` - è®­ç»ƒæ€»ç»“

**ä¿å­˜æ—¶æœº**ï¼šè®­ç»ƒå®Œæˆæ—¶
**å†…å®¹**ï¼šæœ€ç»ˆè®­ç»ƒç»“æœæ€»ç»“

```json
{
  "status": "completed",
  "completion_time": "2024-01-15 14:30:00",
  "best_checkpoint": "logs/body_unet_bs2_lr0.0001_ch32/checkpoints/best_model.ckpt",
  "best_val_mIoU": 0.5234,
  "total_epochs": 100
}
```

---

## ğŸ¯ ä¸»è¦æ”¹è¿›ç‚¹

### 1. **å®Œæ•´çš„è®­ç»ƒä¿¡æ¯è®°å½•**
- âœ… æ¯ä¸ªepochçš„lossã€accuracyã€mIoU
- âœ… å­¦ä¹ ç‡å˜åŒ–æ›²çº¿
- âœ… æœ€ä½³æ¨¡å‹çš„epochå’Œæ€§èƒ½
- âœ… å®æ—¶æ›´æ–°ï¼Œè®­ç»ƒä¸­æ–­ä¹Ÿä¸ä¸¢å¤±

### 2. **ä¼˜åŒ–çš„æ¨¡å‹ä¿å­˜ç­–ç•¥**
- âœ… åªä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆèŠ‚çœç£ç›˜ç©ºé—´ï¼‰
- âœ… å›ºå®šæ–‡ä»¶å `best_model.ckpt`ï¼ˆæ˜“äºä½¿ç”¨ï¼‰
- âœ… ä¸ä¿å­˜ä¸­é—´checkpointï¼ˆé¿å…æ··æ·†ï¼‰

### 3. **é…ç½®å¯è¿½æº¯æ€§**
- âœ… å®Œæ•´è®°å½•æ‰€æœ‰è®­ç»ƒå‚æ•°
- âœ… è®°å½•ç³»ç»Ÿç¯å¢ƒä¿¡æ¯
- âœ… è®°å½•ç±»åˆ«æƒé‡ç»Ÿè®¡
- âœ… è®°å½•æ¨¡å‹å‚æ•°é‡

---

## ğŸ“Š å¦‚ä½•ä½¿ç”¨è¿™äº›æ—¥å¿—

### 1. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
```python
import json
import matplotlib.pyplot as plt

# åŠ è½½è®­ç»ƒæ—¥å¿—
with open('logs/body_unet_bs2_lr0.0001_ch32/training_log.json', 'r') as f:
    log = json.load(f)

history = log['training_history']

# ç»˜åˆ¶Lossæ›²çº¿
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.plot(history['epoch'], history['train_loss'], label='Train')
plt.plot(history['epoch'], history['val_loss'], label='Val')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Curve')

# ç»˜åˆ¶mIoUæ›²çº¿
plt.subplot(1, 3, 2)
plt.plot(history['epoch'], history['val_mIoU'])
plt.xlabel('Epoch')
plt.ylabel('mIoU')
plt.title('Validation mIoU')

# ç»˜åˆ¶å­¦ä¹ ç‡æ›²çº¿
plt.subplot(1, 3, 3)
plt.plot(history['epoch'], history['learning_rate'])
plt.xlabel('Epoch')
plt.ylabel('Learning Rate')
plt.title('Learning Rate Schedule')

plt.tight_layout()
plt.savefig('training_curves.png')
```

### 2. åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°
```python
from pasco.models.body_net import BodyNet

# æœ€ä½³æ¨¡å‹è·¯å¾„åœ¨ training_summary.json ä¸­
checkpoint_path = "logs/body_unet_bs2_lr0.0001_ch32/checkpoints/best_model.ckpt"

model = BodyNet.load_from_checkpoint(checkpoint_path)
model.eval()
```

### 3. å¯¹æ¯”ä¸åŒå®éªŒ
```python
import json
import pandas as pd

experiments = [
    'body_unet_bs2_lr0.0001_ch16',
    'body_unet_bs2_lr0.0001_ch32',
    'body_unet_bs2_lr0.0001_ch64',
]

results = []
for exp in experiments:
    with open(f'logs/{exp}/training_summary.json', 'r') as f:
        summary = json.load(f)

    with open(f'logs/{exp}/training_config.json', 'r') as f:
        config = json.load(f)

    results.append({
        'experiment': exp,
        'best_mIoU': summary['best_val_mIoU'],
        'total_epochs': summary['total_epochs'],
        'base_channels': config['model']['base_channels'],
        'parameters': config['model']['total_parameters'],
    })

df = pd.DataFrame(results)
print(df)
```

---

## ğŸ” è®­ç»ƒè¿‡ç¨‹ç›‘æ§

è®­ç»ƒæœŸé—´å¯ä»¥å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼š

```bash
# æŸ¥çœ‹æœ€æ–°çš„è®­ç»ƒè¿›åº¦
tail -f logs/body_unet_bs2_lr0.0001_ch32/training_log.json

# æˆ–ä½¿ç”¨ watch å®æ—¶ç›‘æ§
watch -n 5 'cat logs/body_unet_bs2_lr0.0001_ch32/training_log.json | jq ".best_metrics"'
```

---

## ğŸ’¾ ç£ç›˜ç©ºé—´ç®¡ç†

**æ”¹è¿›å‰**ï¼š
- ä¿å­˜ top-3 checkpoint + last checkpoint
- æ¯ä¸ªcheckpoint ~80MB (base_channels=32)
- æ€»è®¡: ~320MB

**æ”¹è¿›å**ï¼š
- åªä¿å­˜ best checkpoint
- æ¯ä¸ªcheckpoint ~80MB
- æ€»è®¡: ~80MB

**èŠ‚çœç©ºé—´**: ~75% ğŸ’°

---

## ğŸ“ è®­ç»ƒæ—¥å¿—ç¤ºä¾‹è¾“å‡º

è®­ç»ƒå¼€å§‹æ—¶ï¼š
```
============================================================
Experiment: body_unet_bs2_lr0.0001_ch32_cw0.5_aug
Log directory: logs/body_unet_bs2_lr0.0001_ch32_cw0.5_aug
============================================================

Setting up data...
BodyDataset [train]: 3222 samples
BodyDataset [val]: 403 samples
Train samples: 3222
Val samples: 403

Computing class frequencies...
Class weights - min: 0.123, max: 5.678, mean: 1.234

Creating model...
Total parameters: 20,458,391
Trainable parameters: 20,458,391

Saving training configuration...
Training configuration saved to: logs/body_unet_bs2_lr0.0001_ch32/training_config.json

============================================================
Starting training...
============================================================
```

è®­ç»ƒå®Œæˆæ—¶ï¼š
```
============================================================
Training complete!
============================================================
Best checkpoint: logs/body_unet_bs2_lr0.0001_ch32/checkpoints/best_model.ckpt
Best val mIoU: 0.5234
Training log: logs/body_unet_bs2_lr0.0001_ch32/training_log.json
Config file: logs/body_unet_bs2_lr0.0001_ch32/training_config.json
============================================================

Training summary saved to: logs/body_unet_bs2_lr0.0001_ch32/training_summary.json
Training log saved to: logs/body_unet_bs2_lr0.0001_ch32/training_log.json
```
