# Default training configuration
# Copy this file and modify for different experiments

# Data
data_dir: "Dataset/voxel_data"
split_file: "Dataset/dataset_split.json"
tree_file: "Dataset/tree.json"
dataset_info_file: "Dataset/dataset_info.json"
num_classes: 70
voxel_size: 4.0
volume_size: [144, 128, 268]  # X, Y, Z

# Model
in_channels: 1
base_channels: 32
num_levels: 4

# Dense Bottleneck
growth_rate: 32
dense_layers: 4
bn_size: 4

# Hyperbolic
hyp_embed_dim: 32
hyp_curv: 1.0
hyp_weight: 0.05
hyp_margin: 0.1
hyp_samples_per_class: 64
hyp_num_negatives: 8
hyp_min_radius: 0.1
hyp_max_radius: 2.0

# Training
batch_size: 1
num_workers: 0
epochs: 120
lr: 0.001
weight_decay: 0.00001
grad_clip: 1.0

# AMP
use_amp: true

# Loss
ce_weight: 0.5
dice_weight: 0.5

# LR scheduler
lr_patience: 10
lr_factor: 0.5

# Checkpoint
checkpoint_dir: "checkpoints/lorentz"
save_every: 10
log_dir: "runs/lorentz"

# GPU
gpu_ids: [0, 1]

# Resume (empty string means start fresh)
resume: ""
